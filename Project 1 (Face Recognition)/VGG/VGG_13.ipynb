{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"CSl7WC1jcYh7"},"source":["# Face Recognition"]},{"cell_type":"markdown","metadata":{"id":"wLalSJSvcbpv"},"source":["## Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"j0kl6rdscoPX"},"source":["### Mount Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmyFApf4bEeu"},"outputs":[],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1835,"status":"ok","timestamp":1683884272895,"user":{"displayName":"Bayu Andrianto Wirawan","userId":"01178341082698287927"},"user_tz":-420},"id":"UedTCNOPdLvR","outputId":"f64ef920-5b70-4425-e404-fbb7af2d781e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/Newton AI-Face Recognition Project/2. Model Experiments/VGG'\n","/content\n"]}],"source":["%cd '/content/drive/MyDrive/Newton AI-Face Recognition Project/2. Model Experiments/VGG'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4awK0qsc9Am"},"outputs":[],"source":["directory = '/content/drive/MyDrive/Newton AI-Face Recognition Project/2. Model Experiments/VGG-13'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrC2dGF9dNPV"},"outputs":[],"source":["data_path = '/content/drive/MyDrive/Newton AI-Face Recognition Project/Dataset/SPLIT'"]},{"cell_type":"markdown","metadata":{"id":"z8cMkGDeelBI"},"source":["### Load, Split and Transform Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6v761NdBeev-"},"outputs":[],"source":["from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import Dataset, DataLoader, random_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIYZWkEeesW6"},"outputs":[],"source":["dataset = ImageFolder(data_path)\n","classes = dataset.classes\n","print(classes)"]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, subset, transform=None):\n","        self.subset = subset\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        x, y = self.subset[index]\n","        if self.transform:\n","            x = self.transform(x)\n","        return x, y\n","        \n","    def __len__(self):\n","        return len(self.subset)"],"metadata":{"id":"KjKBlI8RYJS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYW-_RlshyVL"},"outputs":[],"source":["test_ratio = 0.25\n","total_samples = len(dataset)\n","test_samples = int(test_ratio * total_samples)\n","train_samples = total_samples - test_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoqRqnOAif6d"},"outputs":[],"source":["trainset, testset = random_split(dataset, [train_samples, test_samples])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovPlvFJmiwUh"},"outputs":[],"source":["mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.Resize((224, 224)),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])"]},{"cell_type":"code","source":["train_data = MyDataset(trainset, transform=train_transform)\n","test_data = MyDataset(testset, transform=test_transform)"],"metadata":{"id":"kQpUkR4pYzug"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTPglpcxmMms"},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"zrHpqrPEnL62"},"source":["## Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1eTiDNSnOxE"},"outputs":[],"source":["from torchvision.utils import make_grid\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"He3C73VMJSq3"},"outputs":[],"source":["data_iterator = iter(train_loader)\n","images, labels = next(data_iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dbxP7QcRjHn"},"outputs":[],"source":["def show(img, labels):\n","  str_labels = [classes[i] for i in labels]\n","  img = np.transpose(img.numpy(), (1, 2, 0))\n","  img = (img * std) + mean\n","  plt.imshow(img)\n","  plt.title(' '.join(str_labels))\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zicEzZ4TRVBR"},"outputs":[],"source":["show(make_grid(images[:4]), labels[:4])\n","show(make_grid(images[4:8]), labels[4:8])"]},{"cell_type":"markdown","metadata":{"id":"QkbzDlLsTJsu"},"source":["## Build Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvM_xsPltQI-"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","# from torchvision.models import googlenet, GoogLeNet_Weights\n","from torchvision.models import vgg16, VGG16_Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3XH5ePV0e91"},"outputs":[],"source":["def build_model():\n","  model = vgg16(VGG16_Weights.DEFAULT)\n","  # model.fc=nn.Sequential(\n","  #   nn.Linear(in_features=1024,out_features=512),\n","  #   nn.ReLU(),\n","  #   nn.Linear(in_features=512,out_features=128),\n","  #   nn.ReLU(),\n","  #   nn.Linear(in_features=128,out_features=32),\n","  #   nn.ReLU(),\n","  #   nn.Linear(in_features=32,out_features=2,bias=True)\n","  # )\n","  model.fc = nn.Linear(model.fc.in_features, len(classes))\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UpQNelOZI44n"},"outputs":[],"source":["model = build_model()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"markdown","metadata":{"id":"MOUGHT_2Jxx-"},"source":["## Training Model (With GPU)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4z5rkxMaKsJ3"},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","print(device)"]},{"cell_type":"code","source":["def train_engine(train_loader, test_loader, model, criterion, optimizer, \n","                 checkpoint_path, num_epochs=30, early_stopping_patience=5, device=\"cpu\"):\n","    \"\"\"\n","    Train engine function for PyTorch models with checkpointing and early stopping callbacks.\n","\n","    Args:\n","    - train_loader (DataLoader): DataLoader for the training set.\n","    - test_loader (DataLoader): DataLoader for the test set.\n","    - model (nn.Module): PyTorch model to be trained.\n","    - criterion (nn.Module): PyTorch loss function.\n","    - optimizer (nn.Module): PyTorch optimizer.\n","    - checkpoint_path (str): Path to save the model checkpoints.\n","    - early_stopping_patience (int): Number of epochs to wait for the validation loss to improve before stopping early.\n","    - device (str): Device to use for training (\"cpu\" or \"cuda\").\n","\n","    Returns:\n","    - best_epoch (int): The epoch with the best validation loss.\n","    - best_val_loss (float): The best validation loss achieved during training.\n","    \"\"\"\n","\n","    # Move the model and loss function to the specified device\n","    model.to(device)\n","    criterion.to(device)\n","\n","    # Initialize variables for early stopping\n","    best_val_loss = float(\"inf\")\n","    val_losses = []\n","    no_improvement_epochs = 0\n","\n","    # Train the model for a fixed number of epochs\n","    for epoch in range(num_epochs):\n","        # Set the model to training mode\n","        model.train()\n","\n","        # Iterate over the training data\n","        for inputs, labels in train_loader:\n","            # Move the inputs and labels to the specified device\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # Zero the gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Evaluate the model on the test set\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss = 0.0\n","            for inputs, labels in test_loader:\n","                # Move the inputs and labels to the specified device\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # Forward pass\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                # Accumulate the loss\n","                total_loss += loss.item()\n","\n","            # Compute the average validation loss\n","            avg_val_loss = total_loss / len(test_loader)\n","            val_losses.append(avg_val_loss)\n","\n","            # Print the current epoch and validation loss\n","            print(f\"Epoch {epoch+1}/{num_epochs}: Validation loss = {avg_val_loss:.4f}\")\n","\n","            # Checkpoint the model if the validation loss has improved\n","            if avg_val_loss < best_val_loss:\n","                best_val_loss = avg_val_loss\n","                no_improvement_epochs = 0\n","                torch.save(model.state_dict(), checkpoint_path)\n","                print('Validation Loss Improved. Saving Best Model.')\n","            else:\n","                no_improvement_epochs += 1\n","\n","            # Stop early if the validation loss has not improved for a fixed number of epochs\n","            if no_improvement_epochs >= early_stopping_patience:\n","                print(f\"Validation loss has not improved for {early_stopping_patience} epochs. Stopping early.\")\n","                return val_losses, best_val_loss\n","\n","    return val_losses, best_val_loss\n"],"metadata":{"id":"ZzocRybY0Uw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E5Cks6Y_QGje"},"outputs":[],"source":["# Jangan di running - LAMA - Klo mo run un-comment aja\n","\n","# val_losses, best_val_loss = train_engine(train_loader, test_loader, model, criterion, optimizer, \n","#                                          'model_googlenet.pth', device=device)"]},{"cell_type":"code","source":["plt.plot(range(1, len(val_losses)+1), val_losses)\n","plt.title(f'Best Validation loss: {best_val_loss}')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.show()"],"metadata":{"id":"Sf51NYj8VWqZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQ-1SvhDQnXF"},"source":["## Model Evaluation"]},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"7CnRTjGr70wS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7Bi_9jLQW0I"},"outputs":[],"source":["model = build_model()\n","model.load_state_dict(torch.load('model_googlenet.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Vx6rEluRHe2"},"outputs":[],"source":["data_iterator = iter(test_loader)\n","images, labels = next(data_iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zfXqf9mRMbX"},"outputs":[],"source":["outputs = model(images.cuda())\n","_, predictions = torch.max(outputs, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcUOuP_8R9m1"},"outputs":[],"source":["def show(img, labels, preds):\n","  str_labels = [classes[i] for i in labels]\n","  str_preds = [classes[j] for j in preds]\n","  img = np.transpose(img.numpy(), (1, 2, 0))\n","  img = (img * std) + mean\n","  plt.imshow(img)\n","  plt.show()\n","  print('Ground Truth: ', ' '.join(str_labels))\n","  print('Predictions: ', ' '.join(str_preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDy04zkXSlie"},"outputs":[],"source":["show(make_grid(images[:4]), labels[:4], predictions[:4])\n","show(make_grid(images[4:8]), labels[4:8], predictions[4:8])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"936sEjsQTAQB"},"outputs":[],"source":["correct_pred = {name: 0 for name in classes}\n","total_pred = {name: 0 for name in classes}\n","\n","with torch.no_grad():\n","  for data in test_loader:\n","    images, labels = data\n","    outputs = model(images.cuda())\n","    _, predictions = torch.max(outputs, 1)\n","\n","    for label, pred in zip(labels, predictions):\n","      if label == pred:\n","        correct_pred[classes[label]] += 1\n","      total_pred[classes[label]] += 1\n","\n","for class_name, correct_count in correct_pred.items():\n","  class_acc = (correct_count/total_pred[class_name]) * 100\n","  print(f'[Accuracy for class: {class_name}]: {round(class_acc, 2)}')\n","\n","total_correct = 0\n","for count in correct_pred.values():\n","  total_correct += count\n","test_acc = (total_correct/len(test_data)) * 100\n","print(f'Testing Accuracy: {round(test_acc, 2)} %')"]},{"cell_type":"markdown","source":["## Efficiency Metric"],"metadata":{"id":"j6Mei3J41t2S"}},{"cell_type":"code","source":["import time"],"metadata":{"id":"eS6stY_71zKO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ngetest cpu\n","for i in range(5):\n","  t0 = time.time() # return jumlah detik dalam hari itu 9*60*2+14*60+10+5*10^(-3) H*60^2 + M*60 + S + MS*10^(-3)\n","  out = images[1].unsqueeze(0).cuda()\n","t1 = time.time()\n","print(f\"inference on CPU: {t1-t0:.5f}s\")"],"metadata":{"id":"1fuXsTR61_Z8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ngetest gpu\n","model = model.cuda()\n","test_input = images[1].unsqueeze(0).cuda()\n","\n","for i in range(5):\n","  t0 = time.time() # return jumlah detik dalam hari itu 9*60*2+14*60+10+5*10^(-3) H*60^2 + M*60 + S + MS*10^(-3)\n","  out = model(test_input)\n","t1 = time.time()\n","print(f\"inference on GPU: {t1-t0:.5f}s\")"],"metadata":{"id":"fw5MWs6W2k2p"},"execution_count":null,"outputs":[]}]}